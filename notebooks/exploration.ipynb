{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-07T15:14:13.983549Z",
     "start_time": "2025-10-07T15:14:13.975557Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialisation et chargement des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74f87fbc-1469-49eb-8155-c0ef40b545bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du jeu de données (df.head()):\n",
      "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
      "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
      "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
      "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
      "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
      "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
      "\n",
      "   Location Transaction Date  \n",
      "0  Takeaway       2023-09-08  \n",
      "1  In-store       2023-05-16  \n",
      "2  In-store       2023-07-19  \n",
      "3   UNKNOWN       2023-04-27  \n",
      "4  In-store       2023-06-11  \n"
     ]
    }
   ],
   "source": [
    "# Chargement du Dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\fatim\\PycharmProjects\\ProLib#\\House_Pricing\\Data\\dirty_cafe_sales.csv\")\n",
    "\n",
    "# Afficher les premières lignes (Exigence du PDF)\n",
    "print(\"Aperçu du jeu de données :\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "283ee10b-0cf0-4193-a17a-5c693fb79dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Taille du Dataset (lignes, colonnes) :\n",
      "(10000, 8)\n",
      "\n",
      "Information sur les types de données et valeurs non-nulles (df.info()) :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Taille et Types de Variables\n",
    "print(\"\\nTaille du Dataset (lignes, colonnes) :\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\nInformation sur les types de données et valeurs non-nulles  :\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c76e52-92b3-4bb1-acfc-3615c8c9cac7",
   "metadata": {},
   "source": [
    "Le dataset des ventes de café est composé de 10 000 transactions et de 8 colonnes (caractéristiques). L'analyse des types de données et des valeurs non-nulles révèle plusieurs problèmes critiques qui devront être adressés dans la phase de Traitement Avancé.\n",
    "\n",
    "- Problème Critique : Toutes les Colonnes sont de Type Texte (Object) :\n",
    "  # Quantity :Le calcul de la quantité totale vendue est impossible.\n",
    "  # Price Per Unit : Impossible de déterminer le prix moyen ou de détecter les prix aberrants.\n",
    "  # Total Spent\t: La prédiction de la variable cible (revenu) est bloquée car la colonne n'est pas numérique.\n",
    "  # Transaction Date : Les analyses temporelles (ventes par mois/saison) sont impossibles.\n",
    "   -------La transformation des types de données sera la première priorité du nettoyage.\n",
    "-me des Valeurs Manquantes (Non-Null Count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c95ea9b-8970-4c43-a7fe-dc48d38ae2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de valeurs manquantes (NaN) par colonne :\n",
      "Transaction ID         0\n",
      "Item                 333\n",
      "Quantity             138\n",
      "Price Per Unit       179\n",
      "Total Spent          173\n",
      "Payment Method      2579\n",
      "Location            3265\n",
      "Transaction Date     159\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Compte des Valeurs Manquantes\n",
    "print(\"\\nNombre de valeurs manquantes (NaN) par colonne :\")\n",
    "print(df.isnull().sum())\n",
    " \n",
    "# Les colonnes avec des valeurs manquantes devront être imputées ou supprimées lors du Traitement Avancé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418afcbe-e02d-4840-83ba-287dfd7c2353",
   "metadata": {},
   "source": [
    "L'analyse du nombre de valeurs nulles par colonne confirme la nature de \" cafe sales Data\" et met en évidence trois catégories de colonnes à traiter lors de la Phase 3 (Traitement Avancé).\n",
    "\n",
    "Location (32.65% - Élevé) : L'absence de localisation pour près du tiers des ventes est un problème majeur pour l'analyse spatiale et doit être gérée par imputation par le mode (la localisation la plus fréquente) ou en créant une catégorie \"Inconnu\".\n",
    "\n",
    "Payment Method\t(25.79% - Élevé) :Le mode de paiement est manquant pour plus d'un quart des transactions.la meilleure approche sera d'imputer ces valeurs par une catégorie 'MANQUANT' ou 'INCONNU'.\n",
    "\n",
    "Item (3.33%\t- Modéré) : L'article vendu est inconnu pour 333 transactions.\n",
    "\n",
    "Quantity, Price Per Unit, Total Spent, Transaction Date\t( 138 à 179\t≈1.4% à 1.8% -Faible) : Pour les colonnes clés (prix, quantité, date), le taux est gérable. La meilleure pratique sera l'imputation par la médiane pour les valeurs numériques et par le mode pour la date, ou simplement la suppression des lignes concernées si cela n'affecte pas trop l'échantillon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e412f1c2-b291-485f-ac1b-d3ccefe1d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques Descriptives :\n",
      "       Transaction ID   Item Quantity Price Per Unit Total Spent  \\\n",
      "count           10000   9667     9862           9821        9827   \n",
      "unique          10000     10        7              8          19   \n",
      "top       TXN_1961373  Juice        5            3.0         6.0   \n",
      "freq                1   1171     2013           2429         979   \n",
      "\n",
      "        Payment Method  Location Transaction Date  \n",
      "count             7421      6735             9841  \n",
      "unique               5         4              367  \n",
      "top     Digital Wallet  Takeaway          UNKNOWN  \n",
      "freq              2291      3022              159  \n",
      "\n",
      "Fréquence des Catégories de Produits :\n",
      "Item\n",
      "Juice       1171\n",
      "Coffee      1165\n",
      "Salad       1148\n",
      "Cake        1139\n",
      "Sandwich    1131\n",
      "Smoothie    1096\n",
      "Cookie      1092\n",
      "Tea         1089\n",
      "UNKNOWN      344\n",
      "ERROR        292\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Statistiques sur les variables numériques\n",
    "# Nous utilisons 'include=\"all\"' pour voir aussi les statistiques des variables 'object'\n",
    "# Ceci permet de voir le 'top' et la 'frequence' des catégories.\n",
    "print(\"\\nStatistiques Descriptives :\")\n",
    "print(df.describe(include='all'))\n",
    "\n",
    "# Analyser la distribution des catégories clés\n",
    "print(\"\\nFréquence des Catégories de Produits :\")\n",
    "print(df['Item'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4062e1e7-ccd7-41b9-a283-b66529474f43",
   "metadata": {},
   "source": [
    "Colonnes numériques inutilisables : Pour les colonnes Quantity, Price Per Unit, et Total Spent, les statistiques clés comme la moyenne (mean), l'écart-type (std), le minimum (min) et le maximum (max) sont absentes.\n",
    "\n",
    "# Problèmes de Types (Bloquant) : Toutes les colonnes numériques et la colonne de date sont mal lues (object).\n",
    "\n",
    "# Problèmes de Valeurs Manquantes (Élevé) : Les colonnes Location et Payment Method manquent de 25% à 32% des données.\n",
    "\n",
    "# Problèmes de Cohérence (Saisie Sale) : Des valeurs textuelles comme ERROR et UNKNOWN sont présentes dans des colonnes qui devraient être numériques ou catégorielles cohérentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b75cc2-1b68-4a7e-8ac3-a781e84b4616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de valeurs manquantes par colonne :\n",
      "Location            32.65\n",
      "Payment Method      25.79\n",
      "Item                 3.33\n",
      "Price Per Unit       1.79\n",
      "Total Spent          1.73\n",
      "Transaction Date     1.59\n",
      "Quantity             1.38\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Pourcentage de valeurs manquantes\n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "print(\"Pourcentage de valeurs manquantes par colonne :\")\n",
    "print(missing_percentage[missing_percentage > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5f7dbea-c52b-468c-a0fa-48e0d1ab7cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de valeurs uniques pour les colonnes clés :\n",
      "Item                 10\n",
      "Transaction ID    10000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Décompte des valeurs uniques dans les colonnes clés\n",
    "print(\"\\nNombre de valeurs uniques pour les colonnes clés :\")\n",
    "print(df[['Item', 'Transaction ID']].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c598c3f4-4696-4bc8-9adb-c9f4648dd359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examen des 10 valeurs uniques dans les colonnes 'Price Per Unit', 'Total Spent' et 'Quantity' :\n",
      "Price Per Unit\n",
      "3.0        2429\n",
      "4.0        2331\n",
      "2.0        1227\n",
      "5.0        1204\n",
      "1.0        1143\n",
      "1.5        1133\n",
      "ERROR       190\n",
      "UNKNOWN     164\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Total Spent\n",
      "6.0     979\n",
      "12.0    939\n",
      "3.0     930\n",
      "4.0     923\n",
      "20.0    746\n",
      "15.0    734\n",
      "8.0     677\n",
      "10.0    524\n",
      "2.0     497\n",
      "9.0     479\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Quantity\n",
      "5          2013\n",
      "2          1974\n",
      "4          1863\n",
      "3          1849\n",
      "1          1822\n",
      "UNKNOWN     171\n",
      "ERROR       170\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vérification des colonnes numériques pour les incohérences\n",
    "# On vérifie les valeurs uniques des colonnes qui devraient être numériques mais sont 'object'\n",
    "print(\"\\nExamen des 10 valeurs uniques dans les colonnes 'Price Per Unit', 'Total Spent' et 'Quantity' :\")\n",
    "print(df['Price Per Unit'].value_counts().head(10),'\\n')\n",
    "print(df['Total Spent'].value_counts().head(10),'\\n')\n",
    "print(df['Quantity'].value_counts().head(10),'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc22b9-26e2-4eb8-9770-560d60db286d",
   "metadata": {},
   "source": [
    " # La colonne Total Spent est le point le plus faible du dataset et nécessite une résolution urgente.\n",
    "\n",
    "# Hypothèse : La colonne Total Spent a été mal saisie ou a été encodée de manière erronée avec seulement 19 niveaux de facteurs(les différentes catégories uniques que la variable peut prendre)\n",
    "\n",
    "# Tâche avancee (Nettoyage) :  la conversion en float64 , le Modélisateur devra s'assurer que ces 19 valeurs uniques ne masquent pas un problème d'échantillonnage ou de formatage non détecté."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601ed3a3-6014-4039-9ad6-c41133e29004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistiques sur le Total des Ventes :\n",
      "count     9827\n",
      "unique      19\n",
      "top        6.0\n",
      "freq       979\n",
      "Name: Total Spent, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Voir le quantile pour voir la dispersion au-delà de la moyenne\n",
    "print(\"\\nStatistiques sur le Total des Ventes :\")\n",
    "print(df['Total Spent'].describe(percentiles=[.01, .25, .50, .75, .99]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecfe9d59-84b3-4790-9d57-90e31ff1e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Erreur lors de la conversion de la date : time data \"ERROR\" doesn't match format \"%Y-%m-%d\", at position 11. You might want to try:\n",
      "    - passing `format` if your strings have a consistent format;\n",
      "    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    }
   ],
   "source": [
    "#  Conversion de la colonne 'date' en format datetime\n",
    "# Ceci est une étape de \"nettoyage\", mais essentielle à l'exploration\n",
    "try:\n",
    "    df['date'] = pd.to_datetime(df['Transaction Date'])\n",
    "    print(\"\\nConversion de la colonne 'date' en datetime réussie.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur lors de la conversion de la date : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264d5ca-3c56-4259-a334-d45cd9ebe0e8",
   "metadata": {},
   "source": [
    " # Analyse et Visualisation\tBloquée. il n'est pas possible de créer des graphiques d'évolution des ventes dans le temps (Série Temporelle) tant que la colonne Transaction Date n'est pas nettoyée.\n",
    "# Traitement Avancé : Nettoyage\tPriorité Absolue. nécessaire pour la visualisation  de caractéristiques (créer des variables Mois, Jour de la semaine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cce48d2f-70af-4eb0-ba44-07bb9d902d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Période de temps couverte :\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Période couverte par le dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPériode de temps couverte :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate de la première transaction : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransaction Date\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDate de la dernière transaction : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[33m'\u001b[39m\u001b[33mTransaction Date\u001b[39m\u001b[33m'\u001b[39m].max()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6528\u001b[39m, in \u001b[36mSeries.min\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m   6520\u001b[39m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, ndim=\u001b[32m1\u001b[39m))\n\u001b[32m   6521\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(\n\u001b[32m   6522\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6526\u001b[39m     **kwargs,\n\u001b[32m   6527\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m6528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12453\u001b[39m, in \u001b[36mNDFrame.min\u001b[39m\u001b[34m(self, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12446\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmin\u001b[39m(\n\u001b[32m  12447\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  12448\u001b[39m     axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m  12451\u001b[39m     **kwargs,\n\u001b[32m  12452\u001b[39m ):\n\u001b[32m> \u001b[39m\u001b[32m12453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12454\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  12455\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnanops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnanmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12456\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12459\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12460\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:12442\u001b[39m, in \u001b[36mNDFrame._stat_function\u001b[39m\u001b[34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[39m\n\u001b[32m  12438\u001b[39m nv.validate_func(name, (), kwargs)\n\u001b[32m  12440\u001b[39m validate_bool_kwarg(skipna, \u001b[33m\"\u001b[39m\u001b[33mskipna\u001b[39m\u001b[33m\"\u001b[39m, none_allowed=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m> \u001b[39m\u001b[32m12442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_only\u001b[49m\n\u001b[32m  12444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:6478\u001b[39m, in \u001b[36mSeries._reduce\u001b[39m\u001b[34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[39m\n\u001b[32m   6473\u001b[39m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[32m   6474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   6475\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mwith non-numeric dtypes.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   6477\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m6478\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[39m, in \u001b[36mbottleneck_switch.__call__.<locals>.f\u001b[39m\u001b[34m(values, axis, skipna, **kwds)\u001b[39m\n\u001b[32m    145\u001b[39m         result = alt(values, axis=axis, skipna=skipna, **kwds)\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     result = \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[39m, in \u001b[36m_datetimelike_compat.<locals>.new_func\u001b[39m\u001b[34m(values, axis, skipna, mask, **kwargs)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    402\u001b[39m     mask = isna(values)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[32m    407\u001b[39m     result = _wrap_results(result, orig_values.dtype, fill_value=iNaT)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\pandas\\core\\nanops.py:1098\u001b[39m, in \u001b[36m_nanminmax.<locals>.reduction\u001b[39m\u001b[34m(values, axis, skipna, mask)\u001b[39m\n\u001b[32m   1093\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _na_for_min_count(values, axis)\n\u001b[32m   1095\u001b[39m values, mask = _get_values(\n\u001b[32m   1096\u001b[39m     values, skipna, fill_value_typ=fill_value_typ, mask=mask\n\u001b[32m   1097\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m result = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1099\u001b[39m result = _maybe_null_out(result, axis, mask, values.shape)\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\PycharmProjects\\ProLib#\\House_Pricing\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:47\u001b[39m, in \u001b[36m_amin\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_amin\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m           initial=_NoValue, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_minimum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: '<=' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "# Période couverte par le dataset\n",
    "print(\"\\nPériode de temps couverte :\")\n",
    "print(f\"Date de la première transaction : {df['Transaction Date'].min()}\")\n",
    "print(f\"Date de la dernière transaction : {df['Transaction Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28551a80-22b1-4510-b28a-861ab5cd4040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
